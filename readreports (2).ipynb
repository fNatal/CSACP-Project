{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# unable to run as i ran out of limits\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# Helper function to load text from a file (e.g., a report)\n",
    "def load_report(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Function to identify criminal and forensic terminology\n",
    "def detect_criminal_terms(text):\n",
    "    # Basic prompt to detect criminal and forensic terms\n",
    "    prompt = f\"Identify the criminal and forensic terminology used in the following text:\\n\\n{text}\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    result = response['choices'][0]['text'].strip()\n",
    "    return result\n",
    "\n",
    "# Function to tokenize and process text\n",
    "def preprocess_text(text):\n",
    "    # Sentence tokenization\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Word tokenization and stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    filtered_words = [word for word in words if word not in stop_words and word not in string.punctuation]\n",
    "    \n",
    "    return sentences, filtered_words\n",
    "\n",
    "# Function to extract features based on text analysis\n",
    "def extract_features(text):\n",
    "    # Preprocess the text\n",
    "    sentences, words = preprocess_text(text)\n",
    "    \n",
    "    # 1. Sentence Length Feature\n",
    "    sentence_lengths = [len(sentence.split()) for sentence in sentences]\n",
    "    avg_sentence_length = np.mean(sentence_lengths) if sentence_lengths else 0\n",
    "    \n",
    "    # 2. Punctuation Frequency Feature\n",
    "    punctuation_counts = Counter(char for char in text if char in string.punctuation)\n",
    "    total_punctuation = sum(punctuation_counts.values())\n",
    "    punctuation_frequency = {punct: count / total_punctuation for punct, count in punctuation_counts.items()} if total_punctuation else {}\n",
    "    \n",
    "    # 3. POS Tag Frequency Feature\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    pos_tag_counts = Counter(tag for word, tag in pos_tags)\n",
    "    total_pos_tags = sum(pos_tag_counts.values())\n",
    "    pos_tag_distribution = {tag: count / total_pos_tags for tag, count in pos_tag_counts.items()} if total_pos_tags else {}\n",
    "    \n",
    "    # 4. Function Word Frequency Feature (using predefined list)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    function_words = [word for word in words if word in stop_words]\n",
    "    function_word_counts = Counter(function_words)\n",
    "    total_function_words = len(function_words)\n",
    "    function_word_frequencies = {word: count / total_function_words for word, count in function_word_counts.items()} if total_function_words else {}\n",
    "    \n",
    "    # 5. Type-Token Ratio Feature (lexical diversity)\n",
    "    type_token_ratio = len(set(words)) / len(words) if words else 0\n",
    "    \n",
    "    # 6. Passive-to-Active Voice Ratio Feature\n",
    "    passive_to_active_ratio = calculate_passive_to_active_ratio(text)\n",
    "    \n",
    "    # 7. Forensic Term Extraction (using OpenAI API)\n",
    "    forensic_terms = detect_criminal_terms(text)\n",
    "    \n",
    "    # Combine all extracted features into a feature vector\n",
    "    feature_vector = [\n",
    "        avg_sentence_length,\n",
    "        punctuation_frequency,\n",
    "        pos_tag_distribution,\n",
    "        function_word_frequencies,\n",
    "        type_token_ratio,\n",
    "        passive_to_active_ratio,\n",
    "        forensic_terms\n",
    "    ]\n",
    "    \n",
    "    return feature_vector\n",
    "\n",
    "# Function to calculate passive-to-active voice ratio (simplified)\n",
    "def calculate_passive_to_active_ratio(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    passive_count = sum(1 for sentence in sentences if 'by' in sentence and 'was' in sentence)  # very basic check\n",
    "    active_count = len(sentences) - passive_count\n",
    "    return passive_count / active_count if active_count > 0 else 0\n",
    "\n",
    "# Function to prepare data for ML model\n",
    "def prepare_data_for_ml(feature_vectors):\n",
    "    # Convert feature vectors to DataFrame for ML processing\n",
    "    df = pd.DataFrame(feature_vectors)\n",
    "    return df\n",
    "\n",
    "# Main function to process the report and prepare features\n",
    "def process_report(file_path):\n",
    "    # Load the report (text file)\n",
    "    text = load_report(file_path)\n",
    "    \n",
    "    # Extract features from the report\n",
    "    feature_vector = extract_features(text)\n",
    "    \n",
    "    # Prepare the features for the ML model\n",
    "    prepared_data = prepare_data_for_ml([feature_vector])  # Wrapping in a list to keep consistent format\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "# Example usage\n",
    "file_path = 'your-report.txt'  # Path to your text report\n",
    "prepared_data = process_report(file_path)\n",
    "\n",
    "# Show the prepared data (features) ready to be sent to an ML model\n",
    "print(prepared_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
